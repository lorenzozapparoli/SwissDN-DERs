# this is the python script for allocating heat pumps to MV loads
import numpy as np
import pandas as pd
import os
import geopandas as gpd
import json
from scipy.spatial import ConvexHull
from shapely.geometry import Polygon
from shapely.affinity import scale
from scipy.spatial import Voronoi, voronoi_plot_2d
from geovoronoi import voronoi_regions_from_coords, points_to_coords
import tqdm
import warnings
from shapely import wkt
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

'''
   buildings_data.csv:
   EGID: id of the building
   GKODN: x coordinate
   GKODE: y coordinate
   HBLD: thermal conductance in kWh/K
   CBLD: thermal capacity in kWh/K
   PRT: rated power in kW
   GEBF: heating equivalent area
   GAREA: specific surface area
   ISHP: heat pump installation yes/no
   T_PROFILE: temperature profile
   
   gebaeude_batiment_edificio.csv:
   GEBF: heating equivalent area
   GKODE: coordination E
   GKODN: coordination N
   GASTW: number of floor per building
   GANZWHG: number of apartments per building
   GBAUJ: year of construction
   GSTAT: building status
   GAREA: specific surface area
   '''
   
   # INPUT: buildings_data.csv generated by Lorenzo
   # OUPUT: HP_allocation.csv. The file contains the following columns:
    # EGID: id of the building
    # MV_ID: id of the MV
    # MV_osmid: osmid of the MV
    # CBLD: thermal capacity in kWh/m2K
    # HBLD: thermal conductance in kWh/m2K
    # PRT: rated power
    # GEBF: heating equivalent area
    # GAREA: specific surface area
# create HP_allocation_LV folder if it does not exist


# load the data
script_path = os.path.dirname(os.path.abspath(__file__))
data_path = os.path.join(script_path, 'Buildings_data')
grid_path = 'MV/'
buildings_data = pd.read_csv(os.path.join(data_path, 'Buildings_data.csv'), sep=',', low_memory=False)
if not os.path.exists(os.path.join(script_path, 'HP_allocation_LV')):
    os.makedirs(os.path.join(script_path, 'HP_allocation_LV'))

LV_data_path = 'LV/'
dict_path = 'data_processing/'

with open(os.path.join(dict_path, 'dict_folder.json')) as f:
    dict_folder = json.load(f)
municipality_names = pd.read_csv(os.path.join(dict_path, 'dict_grid_municipality.csv'))
municipality_names['municipality'] = municipality_names['municipality'].apply(lambda x: x.replace('/', '_') if '/' in x else x)
len_dict = len(dict_folder)
keys = list(dict_folder.keys())

class HP():
    def __init__(self):
        self.BUFFER_DISTANCE = 10
        self.script_path = os.path.dirname(os.path.abspath(__file__))
        self.data_path = os.path.join(self.script_path, 'Buildings_data')
        self.grid_path = 'LV/'
        self.id = str
        self.municipality = str
        self.exclude_nodes = pd.DataFrame()
        self.save_path = os.path.join(self.script_path, 'HP_allocation_LV')
    
    def load_building_data(self):
        try:
            print('Loading the processed building data...')
            buildings = pd.read_csv(self.data_path+'/Buildings_data_lv.csv')
            buildings['geometry'] = buildings['geometry'].apply(wkt.loads)
            buildings = gpd.GeoDataFrame(buildings, crs='EPSG:2056', geometry=buildings.geometry)
            print('Finish loading the processed building data from the csv file.')
        except:
            buildings = pd.read_csv(self.data_path+'/Buildings_data.csv')
            buildings = gpd.GeoDataFrame(buildings, crs='EPSG:2056', geometry=gpd.points_from_xy(buildings.GKODE, buildings.GKODN))
            buildings['LV_grid'] = -1
            buildings['LV_osmid'] = -1
            print('Transform the building data to the correct coordinate system.')
        return buildings

    def load_grid_data(self):
        # load mv and lv node and edge data
        LV_path = 'LV/'
        lv_node_name = self.id+"_nodes"
        lv_edge_name = self.id+"_edges"
        lv_node_gpd=gpd.read_file(LV_path+dict_folder[HP.municipality]+'/'+lv_node_name)
        lv_edge_gpd=gpd.read_file(LV_path+dict_folder[HP.municipality]+'/'+lv_edge_name)
        lv_node_gpd['osmid'] = lv_node_gpd['osmid'].astype(int)
        lv_node_gpd['consumers'] = lv_node_gpd['consumers'].astype(bool)
        lv_node_gpd['source'] = lv_node_gpd['source'].astype(bool)
        lv_node_gpd.drop(lv_node_gpd[lv_node_gpd['el_dmd']==0].index, inplace=True)
        lv_node_gpd = lv_node_gpd[lv_node_gpd['el_dmd']<=0.1]
        HP.exclude_nodes = pd.concat([HP.exclude_nodes, lv_node_gpd[lv_node_gpd['el_dmd']>0.1]])
        lv_node_gpd.reset_index(drop=True, inplace=True)
        return lv_node_gpd, lv_edge_gpd
    

    def create_convex_hull(self,lv_node_gpd):
        # create convex full for the grids 
        hull = ConvexHull([list(point) for point in lv_node_gpd.geometry.apply(lambda x: (x.x,x.y))])
        hull_points = [lv_node_gpd.geometry.apply(lambda x: (x.x,x.y))[i] for i in hull.vertices]
        polygon = Polygon(hull_points)
        buffered_polygon = polygon.buffer(self.BUFFER_DISTANCE)
        buffered_hull_points = np.array(buffered_polygon.exterior.coords)
        return buffered_polygon, buffered_hull_points

    def find_building_within_hull(self, building, hull):
        points_within_hull = building[(building['LV_grid'] == '-1') | (building['LV_grid'] == -1)]
        points_within_hull = points_within_hull[points_within_hull.geometry.apply(lambda x: hull.contains(x))] 
        return points_within_hull

    def building_allocation(self, buildings, show_plot=False):
        # This function do the voronoi partitioning for the nodes and allocate the buildings to the nodes
        
        lv_node_gpd, lv_edge_gpd = self.load_grid_data()
        buffered_polygon, buffered_hull_points = self.create_convex_hull(lv_node_gpd)
        points_within_hull = self.find_building_within_hull(buildings, buffered_polygon)
        points_within_hull = points_within_hull.reset_index(drop=True)
        if len(points_within_hull) == 0:
            print('No points within the hull.')
        # partition all the mv nodes
        coords = points_to_coords(lv_node_gpd.geometry)
        coords = np.append(coords, buffered_hull_points, axis=0)
        vor = Voronoi(coords)
        regions = vor.regions
        vertices = vor.vertices
        point_region = vor.point_region
        
        print('Allocating buildings to the nodes in grid '+self.id+'...')
        for i in tqdm.tqdm(range(len(lv_node_gpd))):
            cor = coords[i]
            region = regions[point_region[i]]
            if -1 in region:
                region.remove(-1)
            region_vertices = vertices[region]

            for j in range(len(points_within_hull)):
                bd = points_within_hull.iloc[j]
                if bd['geometry'].within(Polygon(region_vertices)):
                    points_within_hull.at[j, 'MV_osmid'] = lv_node_gpd.iloc[i]['osmid']
                    points_within_hull.at[j, 'MV_grid'] = self.id
        print('Building allocation is completed.')

        if show_plot:
            fig, ax = plt.subplots()
            lv_edge_gpd.plot(ax=ax, color='k', linewidth=1)
            voronoi_plot_2d(vor, ax=ax, show_vertices=False, point_size=3, line_colors='grey', line_width=0.5,
                        line_alpha=0.6,show_points=False)
            # if points_within_hull['MV_grid']==-1, plot it in grey, otherwise plot it in darkorange
            points_within_hull[[points_within_hull['MV_grid']=='-1'|points_within_hull['MV_grid']==-1]].plot(ax=ax, color='grey', markersize=0.5)
            points_within_hull[[points_within_hull['MV_grid']!='-1'|points_within_hull['MV_grid']!=-1]].plot(ax=ax, color='slateblue', markersize=0.5)
            lv_node_gpd.plot(ax=ax, color='lightcoral', markersize=5, zorder=5)
            plt.xlim([buffered_polygon.bounds[0]-15, buffered_polygon.bounds[2]+15])
            plt.ylim([buffered_polygon.bounds[1]-15, buffered_polygon.bounds[3]+15])
            plt.savefig(f"{self.script_path}/HP_allocation_{self.id}.png")
            plt.show()
        return points_within_hull
    
    def merge_update(self, building, building_part):
        cols_to_merge = ['EGID', 'LV_grid', 'LV_osmid', 'geometry']
        building = pd.merge(building, building_part[cols_to_merge], how='left', on='EGID',suffixes=('', '_updated'))
        building['LV_grid'] = building['LV_grid_updated'].combine_first(building['LV_grid'])
        building['LV_osmid'] = building['LV_osmid_updated'].combine_first(building['LV_osmid'])
        building['geometry'] = building['geometry_updated'].combine_first(building['geometry'])
        building = building.drop(columns=['LV_grid_updated', 'LV_osmid_updated', 'geometry_updated'])
        return building
        

if __name__ == "__main__":
    HP = HP()
    buildings = HP.load_building_data()
    for key in keys[0:1]:
        HP.exclude_nodes = pd.DataFrame() 
        HP.municipality = key
        print("Processing municipality "+key+" ("+str(list(dict_folder.keys()).index(key)+1)+"/"+str(len_dict)+")")
        path = os.path.join(LV_data_path, dict_folder[key])
        grid_ids = list(set([str(f.split('.')[0][:-6]) for f in os.listdir(path) if f.startswith(key+'-')]))
        print("There are "+str(len(grid_ids))+" grids in this municipality.")
        for id in grid_ids: 
            HP.id = id
            building_partly = HP.building_allocation(buildings, show_plot=False)
            buildings = HP.merge_update(buildings, building_partly)
            index = keys.index(key)
        if index%30 == 0:
            buildings.to_csv(HP.data_path+'/Buildings_data_lv.csv', index=False)
            print("saving the changes of allocation to the csv file." )
        # SAVE EXCLUDE NODES file
        if not HP.exclude_nodes.empty:
            HP.exclude_nodes.to_csv(HP.save_path+'/'+key+'_exclude_nodes.csv', index=False)
    buildings.to_csv(HP.data_path+'/Buildings_data_lv.csv', index=False)
    print("saving the changes of allocation to the csv file." )
    
# TODO: exclude the node with consumption>100kW, the unit of el_dmd is MW DONE
# TODO: parellelize the process
    



